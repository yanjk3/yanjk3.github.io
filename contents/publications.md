For more information, please refer to my [Google Scholar]("https://scholar.google.com.hk/citations?user=QMm29SwAAAAJ&hl=en").

- S. Fu, Q. Yang, Q. Mo, **J. Yan**, X. Wei, J. Meng, X. Xie, W-S. Zheng. LLMDet: Learning Strong Open-Vocabulary Object Detectors under the Supervision of Large Language Models. **In CVPR 2025**. [[ArXiv]](https://arxiv.org/abs/2501.18954) [[Code]](https://github.com/iSEE-Laboratory/LLMDet)

- S. Fu, **J. Yan**, Q. Yang, X. Wei, X. Xie, W-S. Zheng. Frozen-DETR: Enhancing DETR with Image Understanding from Frozen Foundation Models. **In NeurIPS 2024**. [[ArXiv]](https://arxiv.org/abs/2410.19635) [[Paper]](https://proceedings.neurips.cc/paper_files/paper/2024/hash/bf7262e692f3a5c7d676e9e06a1d919a-Abstract-Conference.html) [[Code]](https://github.com/iSEE-Laboratory/Frozen-DETR)

- H. Tian*, J. Meng*, W-S. Zheng, Y-M. Li, **J. Yan**, Y. Zhang. Loc4Plan: Locating Before Planning for Outdoor Vision and Language Navigation. **In ACM-MM 2024 (Oral & Best Paper Nomination)**. [[ArXiv]](https://arxiv.org/abs/2408.05090) [[Paper]](https://dl.acm.org/doi/abs/10.1145/3664647.3681518)

- **J. Yan***, Y. Gao*, Q. Yang, X. Wei, X. Xie, A. Wu, W-S. Zheng. DreamView: Injecting View-specific Text Guidance into Text-to-3D Generation. **In ECCV 2024**. [[ArXiv]](https://arxiv.org/abs/2404.06119) [[Paper]](https://link.springer.com/chapter/10.1007/978-3-031-72698-9_21) [[Code]](https://github.com/iSEE-Laboratory/DreamView)

- Q. Mo, Y. Gao, S. Fu, **J. Yan**, A. Wu, W-S. Zheng. Bridge Past and Future: Overcoming Information Asymmetry in Incremental Object Detection. **In ECCV 2024**. [[ArXiv]](https://arxiv.org/abs/2407.11499) [[Paper]](https://link.springer.com/chapter/10.1007/978-3-031-72640-8_26) [[Code]](https://github.com/iSEE-Laboratory/BPF)

- X. Li*, **J. Yan***, J. Jiang, W-S. Zheng. PTMA: Pre-trained Model Adaptation for Transfer Learning. **In KSEM 2024**. [[Paper]](https://link.springer.com/chapter/10.1007/978-981-97-5492-2_14) 

- W-S. Zheng*, **J. Yan***, Y-X. Peng. A Versatile Framework for Multi-scene Person Re-identification. **IEEE TPAMI, 2024**. [[ArXiv]](https://arxiv.org/abs/2403.11121) [[Paper]](https://ieeexplore.ieee.org/abstract/document/10510353/) [[Code]](https://github.com/iSEE-Laboratory/VersReID)

- S. Fu, **J. Yan**, Y. Gao, X. Xie, W-S. Zheng. ASAG: Building Strong One-Decoder-Layer Sparse Detectors via Adaptive Sparse Anchor Generation. **In ICCV 2023**. [[ArXiv]](https://arxiv.org/abs/2308.09242) [[Paper]](https://openaccess.thecvf.com/content/ICCV2023/html/Fu_ASAG_Building_Strong_One-Decoder-Layer_Sparse_Detectors_via_Adaptive_Sparse_Anchor_ICCV_2023_paper.html) [[Code]](https://github.com/iSEE-Laboratory/ASAG)

- **J. Yan**, L. Yang, Y. Gao, W-S. Zheng. Self-supervised Cross-stage Regional Contrastive Learning for Object Detection. **In ICME 2023 (Oral)**. [[Paper]](https://ieeexplore.ieee.org/document/10219835) [[Code]](https://github.com/yanjk3/CrossCL)

- Y. Gao, K-Y. Lin, **J. Yan**, Y. Wang, W-S. Zheng. AsyFOD: An Asymmetric Adaptation Paradigm for Few-Shot Domain Adaptive Object Detection. **In CVPR 2023**. [[Paper]](http://openaccess.thecvf.com/content/CVPR2023/html/Gao_AsyFOD_An_Asymmetric_Adaptation_Paradigm_for_Few-Shot_Domain_Adaptive_Object_CVPR_2023_paper.html) [[Code]](https://github.com/Hlings/AsyFOD)

- D. Song, Y. Gao, **J. Yan**, W. Sun, W-S. Zheng. Space-correlated Contrastive Representation Learning with Multiple Instances. **In ICPR 2022 (Best Industrial Research Paper Award Candidate)**. [[Paper]](https://ieeexplore.ieee.org/abstract/document/9956034) [[Code]](https://github.com/yanjk3/SpaceCL)
